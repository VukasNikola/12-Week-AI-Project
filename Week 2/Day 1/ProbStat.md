# Statistics & Probability Checklist for AI/ML Proficiency

## Descriptive Statistics  
- [x] **Measures of Central Tendency (Mean, Median, Mode):** These are values representing the center or typical value of a dataset. *Mean* is the average, *median* is the middle value, and *mode* is the most frequent value ([Measures of Center - (AP Statistics) - Vocab, Definition, Explanations](https://library.fiveable.me/key-terms/ap-stats/measures-of-center#:~:text=Explanations%20library,the%20mean%2C%20median%2C%20and)). **Resource:** Khan Academy introductory video on mean, median, and mode.  
- [x] **Measures of Variability (Variance & Standard Deviation):** Quantify the spread of data around the center. *Variance* is the average of squared deviations from the mean, and *standard deviation* is its square root (measured in the data’s units) ([Understanding Central Tendency and Variability in Data Analysis](https://www.coursesidekick.com/statistics/395143#:~:text=Measures%20of%20variability%20include%20variance,Also%20refers%20to%20how)). These indicate how much the data typically varies from the mean. **Resource:** Khan Academy video on variance and standard deviation.  
- [ ] **Correlation & Covariance:** Covariance measures how much two variables vary together, while **correlation** is the standardized form (bounded between -1 and 1) indicating the strength and direction of a linear relationship ([Covariance and Correlation | GeeksforGeeks](https://www.geeksforgeeks.org/mathematics-covariance-and-correlation/#:~:text=Covariance%20Correlation%20Covariance%20is%20a,Provides%20direction%20and%20strength%20of)). A higher absolute correlation means a stronger linear relationship. **Resource:** StatQuest video on correlation and covariance (intuitive explanation).

## Probability Theory  
- [ ] **Basic Probability Concepts:** Probability measures the likelihood of an event occurring, from 0 (impossible) to 1 (certain) ([Flexi answers - What is the probability of an event occurring? - CK-12](https://www.ck12.org/flexi/cbse-math/definition-of-probability/what-is-the-probability-of-an-event-occurring/#:~:text=CK,an%20event%20that%20is)). Important fundamentals include **sample spaces** (all possible outcomes), **events**, and rules like the addition rule for mutually exclusive events and the multiplication rule for independent events. **Resource:** Khan Academy – Probability basics (introductory exercises and videos).  
- [ ] **Conditional Probability & Independence:** *Conditional probability* `P(A|B)` is the probability of event A given that B has occurred. Two events are **independent** if knowing one occurred does not change the probability of the other ([Conditional probability and independence (article) - Khan Academy](https://www.khanacademy.org/math/ap-statistics/probability-ap/stats-conditional-probability/a/check-independence-conditional-probability#:~:text=Conditional%20probability%20and%20independence%20,For%20example%2C%20the%20probability)) (formally, P(A∩B) = P(A)·P(B)). **Bayes’ Theorem** provides a way to update probabilities given new evidence: `Posterior = (Prior × Likelihood) / Evidence`. **Resource:** 3Blue1Brown’s video “Bayes Theorem – The Geometry of Changing Beliefs” (visual explanation of Bayes).  
- [ ] **Random Variables and Expectation:** A **random variable** maps outcomes of a random process to numerical values ([Random variables (video) | Khan Academy](https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/random-variables-discrete/v/random-variables#:~:text=Random%20variables%20%28video%29%20,coin%20or%20you%27re%20rolling)). Discrete random variables have probability mass functions (PMFs) and continuous ones have density functions (PDFs). Key properties include the **expected value** (mean of the random variable’s distribution) and **variance**. The **linearity of expectation** (E[X+Y] = E[X]+E[Y]) is useful, and the **Law of Large Numbers** says sample averages converge to the expected value as sample size grows. **Resource:** Khan Academy – Random variables and probability distribution (interactive exercises).

## Probability Distributions (Discrete & Continuous)  

| **Distribution**        | **Brief Explanation**                                    | **Learning Resource**               |
|-------------------------|---------------------------------------------------------|-------------------------------------|
| **Bernoulli Distribution** (discrete)  | Models a single trial with two outcomes: success (1) with probability *p*, or failure (0) with probability *q = 1-p*. It’s the simplest distribution for binary events ([Common Statistical Terms Every Data Scientist Should Know | by Praise James | Medium](https://medium.com/@techwithpraisejames/common-statistical-terms-every-data-scientist-should-know-b8ac4f35d051#:~:text=2,failure%20and%201%20%3D%20success)). | Khan Academy – Probability basics (covers simple 0/1 outcomes) |
| **Binomial Distribution** (discrete)  | Distribution of the number of successes in *n* independent Bernoulli trials with success probability *p*. It gives the probability of getting k successes out of n trials ([The Binomial Random Variable | Boundless Statistics | ](https://www.coursesidekick.com/statistics/study-guides/boundless-statistics/the-binomial-random-variable#:~:text=In%20probability%20theory%20and%20statistics%2C,successes%20in%20a%20sequence%20of)). (The Bernoulli is a special case with n=1.) | Khan Academy – Binomial distribution (video examples) |
| **Poisson Distribution** (discrete)  | Models the count of events in a fixed interval of time or space under a constant average rate (λ) and independent occurrences. Useful for rare events counts (e.g. number of website hits per minute) ([Common Statistical Terms Every Data Scientist Should Know | by Praise James | Medium](https://medium.com/@techwithpraisejames/common-statistical-terms-every-data-scientist-should-know-b8ac4f35d051#:~:text=2,failure%20and%201%20%3D%20success)). | StatQuest – Poisson distribution explained (YouTube) |
| **Uniform Distribution** (continuous or discrete) | All outcomes are equally likely. In a discrete uniform distribution (e.g. rolling a fair die), each outcome has equal probability. In a continuous uniform distribution on [a, b], any value in the interval is equally likely ([Uniform Distribution - Overview, Examples, Types](https://corporatefinanceinstitute.com/resources/data-science/uniform-distribution/#:~:text=,statistical%20analysis%20and%20probability%20theory)). | MIT OCW – Uniform distribution (lecture notes/video) |
| **Normal (Gaussian) Distribution** (continuous) | A symmetric, bell-shaped distribution defined by mean μ and standard deviation σ. Many natural phenomena approximate normal. About 68% of values lie within 1σ, ~95% within 2σ of the mean ([Common Statistical Terms Every Data Scientist Should Know | by Praise James | Medium](https://medium.com/@techwithpraisejames/common-statistical-terms-every-data-scientist-should-know-b8ac4f35d051#:~:text=1,failure%20and%201%20%3D%20success)). Widely used in CLT and error analysis. | Khan Academy – Introduction to the normal distribution (video) |
| **Exponential Distribution** (continuous) | Models the time between independent events occurring at a constant rate (memoryless property). It’s the continuous analog of the geometric distribution. For rate λ, the PDF is λ·e<sup>–λx</sup>, x ≥ 0 ([Exercise 79, Chapter 4: Continuous Random Variables and ... - Brainly](https://brainly.com/textbook-solutions/q-79-event-x-2-y-equivalent-event-i3x16c#:~:text=Brainly%20brainly,a%20Poisson%20point%20process)). (Used for modeling lifetimes or interarrival times.) | Khan Academy – Exponential distribution (article & video) |

## Inferential Statistics  
- [ ] **Sampling Distributions & Central Limit Theorem (CLT):** The **sampling distribution** of a statistic (like the sample mean) is the distribution of that statistic over all possible samples. The CLT states that as sample size n grows, the distribution of sample means approaches a normal distribution (with mean = population mean and variance = σ²/n), regardless of the population’s distribution ([ Unlocking the Power of Normal Distribution in Machine Learning: Why It Matters and How to Detect It | by Rohan Mistry | Mar, 2025 | Medium](https://medium.com/@rohanmistry231/unlocking-the-power-of-normal-distribution-in-machine-learning-why-it-matters-and-how-to-f4019922cb02#:~:text=2)). This underpins why we can use normal-based confidence intervals and tests even for non-normal data (with large n). **Resource:** Khan Academy – Central Limit Theorem (illustrative simulations).  
- [ ] **Confidence Intervals:** A **confidence interval** gives a range of values believed to contain the true population parameter with a certain confidence level (e.g. 95%). For example, a 95% CI for a mean might be $\bar{x} \pm 1.96\frac{s}{\sqrt{n}}$. It is computed from sample data and is interpreted as: “we are 95% confident the true parameter lies in this range” ([Confidence Intervals for Business Analytics | by Kyle Jones - Medium](https://medium.com/@kylejones_47003/confidence-intervals-c3a1605bfb55#:~:text=Medium%20medium,is%20calculated%20from%20sample%20data)). (Important: 95% of such intervals from repeated samples would contain the true value.) **Resource:** StatQuest – Confidence intervals clearly explained (video).  
- [ ] **Hypothesis Testing (Significance Tests):** A formal procedure to test assumptions about a population parameter. We set up a **null hypothesis** (no effect or status quo) and an **alternative hypothesis**. We then compute a test statistic (e.g. Z, t, χ²) and a **p-value**, which is the probability of observing data as extreme as ours if the null hypothesis is true. If p-value < α (significance level, e.g. 0.05), we reject the null hypothesis ([Hypothesis Testing (5 of 5) | Concepts in Statistics - Lumen Learning](https://courses.lumenlearning.com/wm-concepts-statistics/chapter/introduction-to-hypothesis-testing-5-of-5/#:~:text=Hypothesis%20Testing%20,null%20hypothesis%3A%20When%20we)). This suggests the result is statistically significant. Common tests include the t-test (for means), chi-square tests (for categorical data), and ANOVA (for comparing means across groups). **Resource:** Khan Academy – Hypothesis testing and p-values (video series with examples).  

## Bayesian Methods  
- [ ] **Bayes’ Theorem & Bayesian Inference:** Bayesian methods incorporate prior knowledge into probability analysis. **Bayes’ Theorem** is used to update a prior belief into a **posterior** probability given new evidence: $P(Hypothesis|Data) = \frac{P(Data|Hypothesis)\,P(Hypothesis)}{P(Data)}$. In practice, you choose a **prior distribution** for parameters, use the data (likelihood) to obtain a **posterior distribution**. This framework treats unknown parameters as random variables with distributions. It contrasts with frequentist methods by allowing probability statements about parameters. For example, a **Naïve Bayes classifier** uses Bayes’ rule assuming feature independence. Bayesian inference is powerful in machine learning for incorporating domain knowledge and handling uncertainty ([3Blue1Brown - Bayes' theorem](https://www.3blue1brown.com/lessons/bayes-theorem#:~:text=Bayes%E2%80%99%20theorem%20is%20relevant%20in,that%20the%20evidence%20is%20true)). **Resource:** 3Blue1Brown’s “Bayes Theorem” interactive lesson (visual and intuitive understanding).  
- [ ] **Prior and Posterior Distributions:** In Bayesian statistics, the **prior** represents your belief about a parameter before seeing data, and the **posterior** represents the updated belief after considering the data. The influence of the prior diminishes with more data (the likelihood dominates). Understanding conjugate priors (which yield posteriors in the same family) can simplify analytical solutions. **Resource:** Khan Academy – Bayesian updating (conceptual article).  
- [ ] **Markov Chain Monte Carlo (MCMC)** (Advanced): A class of algorithms (e.g. Metropolis-Hastings, Gibbs sampling) used to approximate complex posterior distributions. MCMC constructs a Markov chain that has the target posterior as its equilibrium distribution, allowing sampling when direct calculation is infeasible. This is key in Bayesian deep learning and probabilistic modeling. **Resource:** Statistical Rethinking (free lecture series) – Introduction to MCMC.

## Statistical Modeling  
- [ ] **Linear Regression:** A fundamental model for predicting a continuous outcome using one or more features (independent variables) by fitting a linear equation $y = \beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p$. The goal is to find the parameters (β coefficients) that minimize error (often using Ordinary Least Squares). Linear regression assumes a roughly linear relationship and is easy to interpret ([Linear Regression – ML with Ramin](https://www.mlwithramin.com/blog/linear-regression#:~:text=Linear%20regression%20is%20a%20basic,a%20set%20of%20predictor)). It’s used in trend analysis and as a building block for more complex models. **Resource:** Khan Academy – Linear regression (interactive tutorial) / StatQuest – Linear Regression (clear explanation video).  
- [ ] **Logistic Regression:** A classification model (technically a generalized linear model) used for binary outcomes (yes/no). It estimates the probability of the positive class using the logistic (sigmoid) function: $P(Y=1) = \frac{1}{1+e^{-(\beta_0+\beta_1 x_1+...+\beta_p x_p)}}$. The model is trained by Maximum Likelihood Estimation. It’s a **statistical method for predicting binary classes**, outputting probabilities that an input belongs to a class ([Logistic Regression - LabEx](https://flashcard.labex.io/html/sklearn-logistic-regression#:~:text=Logistic%20Regression%20,to%20a%20certain%20class)). Widely used for problems like spam detection (outputting probability of “spam”). **Resource:** freeCodeCamp – Logistic Regression tutorial (YouTube full course).  
- [ ] **Maximum Likelihood Estimation (MLE):** A general method to estimate model parameters by finding values that **maximize the likelihood** of observing the given data. In other words, MLE chooses parameters that make the data “most probable”. This means setting up a likelihood function $L(\theta) = P(\text{Data}|\theta)$ and finding the $\theta$ that maximizes it ([Probability concepts explained: Maximum likelihood estimation | by Jonny Brooks-Bartlett | TDS Archive | Medium](https://medium.com/towards-data-science/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1#:~:text=Maximum%20likelihood%20estimation%20is%20a,data%20that%20were%20actually%20observed)). MLE underlies the training of many models (e.g. fitting logistic regression, neural network weights via cross-entropy is an MLE approach). **Resource:** StatQuest – Maximum Likelihood Estimation (video with simple examples).  
- [ ] **Evaluation & Model Selection:** Techniques like **train/test split** and **cross-validation** are crucial for assessing model performance on unseen data and avoiding overfitting. **Metrics** such as accuracy, precision/recall (for classification) and RMSE or R² (for regression) quantify performance. Understanding these helps in comparing models. **Resource:** freeCodeCamp – Model evaluation (interactive article).  
- [ ] **Regularization:** Methods like Lasso (L1) and Ridge (L2) regularization add penalties to the loss function to discourage complex models (large coefficients). This helps prevent overfitting by trading a bit of bias for lower variance. Regularization is a practical aspect of statistical modeling connecting to the bias-variance tradeoff. **Resource:** StatQuest – L1 vs L2 regularization (video).  

## Information Theory  
- [ ] **Entropy:** In information theory, **entropy** is a measure of uncertainty or information content in a random variable. Formally, for distribution *p*, $H(p) = -\sum_x p(x)\log_2 p(x)$. Higher entropy means more unpredictability. For example, a fair coin toss has 1 bit of entropy. Entropy is foundational for quantifying information ([Kullback-Leibler Divergence | GeeksforGeeks](https://www.geeksforgeeks.org/kullback-leibler-divergence/#:~:text=Entropy%3A%20Entropy%20is%20a%20way,of%20a%20random%20variable%20X)). (In ML, entropy is used in decision tree splits and as the theoretical underpinning of loss functions.) **Resource:** StatQuest – *Entropy (for data science) Clearly Explained* (video).  
- [ ] **Cross-Entropy:** Cross-entropy measures the difference between two probability distributions. If *p* is the true distribution and *q* is a model’s predicted distribution, cross-entropy $H(p,q) = -\sum_x p(x)\log q(x)$. It increases as *q* diverges from *p* ([Kullback-Leibler Divergence | GeeksforGeeks](https://www.geeksforgeeks.org/kullback-leibler-divergence/#:~:text=Kullback,given%20random%20variable%20or)). In ML, **cross-entropy loss** is commonly used for classification (if the model predicts the true class with high probability, the cross-entropy is low). Minimizing cross-entropy is equivalent to maximizing likelihood. **Resource:** Machine Learning Mastery – *A Friendly Introduction to Cross-Entropy* (article with examples).  
- [ ] **Kullback–Leibler (KL) Divergence:** KL divergence (relative entropy) is a non-symmetric measure of how one distribution *q* “diverges” from another reference distribution *p*. $D_{KL}(p \parallel q) = \sum_x p(x)\log\frac{p(x)}{q(x)}$. It’s 0 if distributions are identical and >0 otherwise ([Kullback-Leibler Divergence | GeeksforGeeks](https://www.geeksforgeeks.org/kullback-leibler-divergence/#:~:text=Kullback,calculated%20by%20the%20following%20formula)). In ML, KL divergence appears in terms like regularizing learned distributions (e.g. in Variational Autoencoders) or measuring information loss. **Resource:** 3Blue1Brown – *Visualizing KL Divergence* (YouTube explanation).  
- [ ] **Mutual Information:** A measure of the mutual dependence between two variables. $I(X;Y) = H(X) + H(Y) - H(X,Y)$. It quantifies how much knowing one variable reduces uncertainty about the other. Mutual information is used in feature selection (to gauge feature relevance) and in understanding attention mechanisms in neural networks. **Resource:** Coursera (Week on Information Theory in ML course, free audit available).  

## Markov Chains (Advanced)  
- [ ] **Markov Chains:** A Markov chain is a stochastic process with the **Markov property** – the next state depends only on the current state (memoryless). It consists of states and transition probabilities between states. For example, a weather model might have states {Sunny, Rainy} and probabilities P(Rainy tomorrow | Sunny today), etc. Markov chains can be described by a transition matrix. They are used in algorithms like PageRank and in **Hidden Markov Models** for sequence data ([Origin of Markov chains (video) - Khan Academy](https://www.khanacademy.org/computing/computer-science/informationtheory/moderninfotheory/v/markov_chains#:~:text=Origin%20of%20Markov%20chains%20,is%20why%20it%27s%20a%20chain)). Understanding Markov chains is also a stepping stone to **Markov Chain Monte Carlo** methods. **Resource:** Khan Academy – *Introduction to Markov Chains* (video in “Journey into Information Theory” series).  
- [ ] **Hidden Markov Models (HMMs):** (Optional) An extension where the state is not directly observed (hidden) but outputs (emissions) are observed. HMMs are applied in speech recognition and bioinformatics. (This is an advanced topic combining Markov chains and Bayesian inference.) **Resource:** Udacity free course – Intro to HMMs.

## Statistical Learning Theory (Advanced)  
- [ ] **Bias–Variance Tradeoff:** Fundamental to understanding model generalization. *Bias* is error due to wrong assumptions (underfitting), *variance* is error due to sensitivity to fluctuations in the training set (overfitting). There is a tradeoff: as a model becomes more complex, bias decreases but variance increases. An optimal model finds the right balance ([ Unlocking the Power of Normal Distribution in Machine Learning: Why It Matters and How to Detect It | by Rohan Mistry | Mar, 2025 | Medium](https://medium.com/@rohanmistry231/unlocking-the-power-of-normal-distribution-in-machine-learning-why-it-matters-and-how-to-f4019922cb02#:~:text=,ANOVA%20need%20normally%20distributed%20data)). This concept explains why an overly complex model might perform poorly on new data and underpins techniques like cross-validation and regularization. **Resource:** StatQuest – Bias vs Variance (video).  
- [ ] **VC Dimension & Model Capacity:** **VC (Vapnik–Chervonenkis) dimension** is a measure of a model’s capacity (complexity) – informally, the largest number of points that the model can shatter (exactly classify in all label configurations). Higher VC dimension means the model can fit more complicated patterns but also risks overfitting. Statistical learning theory provides bounds (e.g., VC bounds) on a model’s generalization error in terms of its complexity and training sample size. **Resource:** MIT OCW – Learning Theory (lecture notes on VC dimension).  
- [ ] **PAC Learning:** *Probably Approximately Correct* learning is a framework that formalizes what it means for a class of functions to be learnable in polynomial time. A concept is PAC-learnable if, for any ε and δ, there exists an algorithm that with probability ≥(1–δ) finds a hypothesis with error ≤ε using polynomial samples and time. This is theoretical but gives insight into feasibility of learning. **Resource:** Caltech “Learning from Data” course (covers PAC theory).  
- [ ] **Generalization and Overfitting:** Understanding **overfitting** (when a model performs well on training data but poorly on new data) is crucial. It relates to having more parameters than necessary or not enough training data. Strategies to improve generalization include using more data, simplifying the model, regularization, and dropout (in neural nets). **Resource:** Google Machine Learning Crash Course – Regularization section (interactive).  

Each topic above includes a brief explanation and a recommended free resource (video or interactive tutorial) for further learning. By mastering this checklist – from basic statistics through advanced probability and learning theory – an intermediate learner will build a strong foundation for AI, Machine Learning, Deep Learning, and understanding the principles behind Large Language Models. Good luck with your studies!  ([Kullback-Leibler Divergence | GeeksforGeeks](https://www.geeksforgeeks.org/kullback-leibler-divergence/#:~:text=Entropy%3A%20Entropy%20is%20a%20way,of%20a%20random%20variable%20X)) ([Covariance and Correlation | GeeksforGeeks](https://www.geeksforgeeks.org/mathematics-covariance-and-correlation/#:~:text=Covariance%20Correlation%20Covariance%20is%20a,Provides%20direction%20and%20strength%20of)) ([Common Statistical Terms Every Data Scientist Should Know | by Praise James | Medium](https://medium.com/@techwithpraisejames/common-statistical-terms-every-data-scientist-should-know-b8ac4f35d051#:~:text=2,failure%20and%201%20%3D%20success)) ([The Binomial Random Variable | Boundless Statistics | ](https://www.coursesidekick.com/statistics/study-guides/boundless-statistics/the-binomial-random-variable#:~:text=In%20probability%20theory%20and%20statistics%2C,successes%20in%20a%20sequence%20of)) ([ Unlocking the Power of Normal Distribution in Machine Learning: Why It Matters and How to Detect It | by Rohan Mistry | Mar, 2025 | Medium](https://medium.com/@rohanmistry231/unlocking-the-power-of-normal-distribution-in-machine-learning-why-it-matters-and-how-to-f4019922cb02#:~:text=2)) ([Probability concepts explained: Maximum likelihood estimation | by Jonny Brooks-Bartlett | TDS Archive | Medium](https://medium.com/towards-data-science/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1#:~:text=Maximum%20likelihood%20estimation%20is%20a,data%20that%20were%20actually%20observed))

